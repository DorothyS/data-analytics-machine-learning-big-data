{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import environ, path\n",
    "environ[\"SPARK_HOME\"] = \"/home/students/spark-2.2.0\"\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Some Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SparkContext and a SQLContext context to use\n",
    "sc = SparkContext(appName=\"SanFran Parking\")\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module Constants\n",
    "DATA_FILE = \"/home/students/data/sf_parking/sf_parking_clean.json\"\n",
    "SAVE_DIR = '{}/model'.format(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data - creates a Spark dataframe\n",
    "parking = sqlContext.read.json(DATA_FILE)\n",
    "print(type(parking))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show 10 rows\n",
    "parking.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the Schema and Change Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the schema\n",
    "parking.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to convert columns to a new type\n",
    "def convert_column(df, col, new_type):\n",
    "    old_col = '%s_old' % col\n",
    "    df = df.withColumnRenamed(col, old_col)\n",
    "    df = df.withColumn(col, df[old_col].cast(new_type))\n",
    "    df = df.drop(old_col)\n",
    "    return df\n",
    "\n",
    "# Columns to convert\n",
    "int_columns = ['regcap', 'valetcap', 'mccap']\n",
    "\n",
    "# Convert the columns\n",
    "for col in int_columns:\n",
    "    parking = convert_column(parking, col, 'int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the new schema\n",
    "parking.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show 10 rows\n",
    "parking.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Query a Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parking.registerTempTable(\"park\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a SQL query against the table\n",
    "aggr_by_type = sqlContext.sql(\"SELECT primetype, secondtype, count(1) AS count, round(avg(regcap), 0) AS avg_spaces \" +\n",
    "                              \"FROM park \" +\n",
    "                              \"GROUP BY primetype, secondtype \" +\n",
    "                              \"HAVING trim(primetype) != '' \" +\n",
    "                              \"ORDER BY count DESC\")\n",
    "\n",
    "aggr_by_type.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(aggr_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can rewrite the SQL query in the previous example by chaining several simple DataFrame operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "aggr_by_type = parking.select(\"primetype\", \"secondtype\", \"regcap\") \\\n",
    "    .where(\"trim(primetype) != ''\") \\\n",
    "    .groupBy(\"primetype\", \"secondtype\") \\\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"count\"),\n",
    "        F.round(F.avg(\"regcap\"), 0).alias(\"avg_spaces\")\n",
    "        ) \\\n",
    "    .sort(\"count\", ascending=False)\n",
    "\n",
    "aggr_by_type.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Describe and Crosstab to Summarize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run describe - like in Pandas\n",
    "parking.describe(\"regcap\", \"valetcap\", \"mccap\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use crosstab\n",
    "parking.stat.crosstab(\"owner\", \"primetype\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Neighborhood Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define another function that will take a “location_1” struct type and use Google’s Geocoding API to perform a lookup on the latitude and longitude to return the neighborhood name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def to_neighborhood(location):\n",
    "    \"\"\"\n",
    "    Uses Google's Geocoding API to perform a reverse-lookup on latitude and\n",
    "    longitude\n",
    "    https://developers.google.com/maps/documentation/geocoding/\n",
    "    intro#reverse-example\n",
    "    \"\"\"\n",
    "    name = 'N/A'\n",
    "    lat = location.latitude\n",
    "    long = location.longitude\n",
    "\n",
    "    r = requests.get(\n",
    "        'https://maps.googleapis.com/maps/api/geocode/json?latlng=%s,%s' %(lat, long))\n",
    "\n",
    "    if r.status_code == 200:\n",
    "        content = r.json()\n",
    "        # results is a list of matching places\n",
    "        places = content['results']\n",
    "        neighborhoods = [p['formatted_address'] for p in places if\n",
    "        'neighborhood' in p['types']]\n",
    "\n",
    "    if neighborhoods:\n",
    "        # Addresses are formatted as Japantown, San Francisco, CA\n",
    "        # so split on comma and just return neighborhood name\n",
    "        name = neighborhoods[0].split(',')[0]\n",
    "\n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pyspark.sql.functions module provides the udf function to register a user-defined function (UDF). We declare an inline UDF by passing UDF a callable Python function and the Spark SQL data type that corresponds to the return type.\n",
    "\n",
    "In this case, we are returning a string so we will use the StringType data type from pyspark.sql.types. Once registered, we can use the UDF to reformat the “location_1” column with a withColumn expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_to_neighborhood=udf(to_neighborhood, StringType())\n",
    "\n",
    "sfmta_parking = parking.filter(parking.owner == 'SFMTA') \\\n",
    "    .select(\"location_1\", \"primetype\", \"landusetyp\",\"garorlot\", \"regcap\", \"valetcap\", \"mccap\") \\\n",
    "    .withColumn(\"location_1\",location_to_neighborhood(\"location_1\")) \\\n",
    "    .sort(\"regcap\", ascending=False)\n",
    "\n",
    "sfmta_parking.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shut it down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from os import getlogin, path\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home Directory: /home/robert.dempsey\n",
      "Data Directory: /home/robert.dempsey/data\n",
      "SanFran Parking Directory: /home/robert.dempsey/data/sanfranparking\n"
     ]
    }
   ],
   "source": [
    "# Module Constants\n",
    "HOME_DIR = path.join(\"/home\", getlogin())\n",
    "DATA_DIR = path.join(HOME_DIR, \"data\")\n",
    "SANFRAN_PARKING_DIR = path.join(DATA_DIR, \"sanfranparking\")\n",
    "\n",
    "print(\"Home Directory: {}\".format(HOME_DIR))\n",
    "print(\"Data Directory: {}\".format(DATA_DIR))\n",
    "print(\"SanFran Parking Directory: {}\".format(SANFRAN_PARKING_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SparkContext and a SQLContext context to use\n",
    "sc = SparkContext(appName=\"SanFran Parking\")\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Load the data - creates a Spark dataframe\n",
    "parking_file = \"/Users/robert.dempsey/Dev/daamlobd/data/sf_parking/sf_parking_clean.json\"\n",
    "parking = sqlContext.read.json(parking_file)\n",
    "print(type(parking))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+----------+--------------------+-----+----------+---------+------+----------+--------+\n",
      "|             address|garorlot|landusetyp|          location_1|mccap|     owner|primetype|regcap|secondtype|valetcap|\n",
      "+--------------------+--------+----------+--------------------+-----+----------+---------+------+----------+--------+\n",
      "|      2110 Market St|       L|restaurant|[37.767378,-122.4...|    0|   Private|      PPA|    13|          |       0|\n",
      "|         993 Potrero|       L|          |[37.757272,-122.4...|    0|     SFMTA|      PPA|    34|          |       0|\n",
      "|601 Terry A Franc...|       L|          |[37.770135,-122.3...|    0|Port of SF|      PPA|    72|          |       0|\n",
      "|   11 SOUTH VAN NESS|       G|          |[37.77415,-122.41...|    0|   Private|      PHO|   130|       CPO|       0|\n",
      "|   101 CALIFORNIA ST|       G|          |[37.793243,-122.3...|    0|   Private|      PPA|   250|          |       0|\n",
      "|        2000 POST ST|       G|          |[37.785078,-122.4...|    0|   Private|      PPA|   304|          |       0|\n",
      "|   600 CALIFORNIA ST|       G|          |[37.792779,-122.4...|    0|   Private|      PPA|   197|          |       0|\n",
      "|       35 GILBERT ST|        |          |[37.774337,-122.4...|    0|   Private|      PPA|    80|          |       0|\n",
      "|        2355 POST ST|       L|          |[37.78397,-122.44...|    0|   Private|      PPA|    50|          |       0|\n",
      "|      801 STANYAN ST|       L|          |[37.767202,-122.4...|    0|       RPD|      PPA|   324|          |       0|\n",
      "+--------------------+--------+----------+--------------------+-----+----------+---------+------+----------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show 10 rows\n",
    "parking.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the Schema and Change Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- address: string (nullable = true)\n",
      " |-- garorlot: string (nullable = true)\n",
      " |-- landusetyp: string (nullable = true)\n",
      " |-- location_1: struct (nullable = true)\n",
      " |    |-- latitude: string (nullable = true)\n",
      " |    |-- longitude: string (nullable = true)\n",
      " |    |-- needs_recoding: boolean (nullable = true)\n",
      " |-- mccap: string (nullable = true)\n",
      " |-- owner: string (nullable = true)\n",
      " |-- primetype: string (nullable = true)\n",
      " |-- regcap: string (nullable = true)\n",
      " |-- secondtype: string (nullable = true)\n",
      " |-- valetcap: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Examine the schema\n",
    "parking.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to convert columns to a new type\n",
    "def convert_column(df, col, new_type):\n",
    "    old_col = '%s_old' % col\n",
    "    df = df.withColumnRenamed(col, old_col)\n",
    "    df = df.withColumn(col, df[old_col].cast(new_type))\n",
    "    df = df.drop(old_col)\n",
    "    return df\n",
    "\n",
    "# Columns to convert\n",
    "int_columns = ['regcap', 'valetcap', 'mccap']\n",
    "\n",
    "# Convert the columns\n",
    "for col in int_columns:\n",
    "    parking = convert_column(parking, col, 'int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- address: string (nullable = true)\n",
      " |-- garorlot: string (nullable = true)\n",
      " |-- landusetyp: string (nullable = true)\n",
      " |-- location_1: struct (nullable = true)\n",
      " |    |-- latitude: string (nullable = true)\n",
      " |    |-- longitude: string (nullable = true)\n",
      " |    |-- needs_recoding: boolean (nullable = true)\n",
      " |-- owner: string (nullable = true)\n",
      " |-- primetype: string (nullable = true)\n",
      " |-- secondtype: string (nullable = true)\n",
      " |-- regcap: integer (nullable = true)\n",
      " |-- valetcap: integer (nullable = true)\n",
      " |-- mccap: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the new schema\n",
    "parking.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+----------+--------------------+----------+---------+----------+------+--------+-----+\n",
      "|             address|garorlot|landusetyp|          location_1|     owner|primetype|secondtype|regcap|valetcap|mccap|\n",
      "+--------------------+--------+----------+--------------------+----------+---------+----------+------+--------+-----+\n",
      "|      2110 Market St|       L|restaurant|[37.767378,-122.4...|   Private|      PPA|          |    13|       0|    0|\n",
      "|         993 Potrero|       L|          |[37.757272,-122.4...|     SFMTA|      PPA|          |    34|       0|    0|\n",
      "|601 Terry A Franc...|       L|          |[37.770135,-122.3...|Port of SF|      PPA|          |    72|       0|    0|\n",
      "|   11 SOUTH VAN NESS|       G|          |[37.77415,-122.41...|   Private|      PHO|       CPO|   130|       0|    0|\n",
      "|   101 CALIFORNIA ST|       G|          |[37.793243,-122.3...|   Private|      PPA|          |   250|       0|    0|\n",
      "|        2000 POST ST|       G|          |[37.785078,-122.4...|   Private|      PPA|          |   304|       0|    0|\n",
      "|   600 CALIFORNIA ST|       G|          |[37.792779,-122.4...|   Private|      PPA|          |   197|       0|    0|\n",
      "|       35 GILBERT ST|        |          |[37.774337,-122.4...|   Private|      PPA|          |    80|       0|    0|\n",
      "|        2355 POST ST|       L|          |[37.78397,-122.44...|   Private|      PPA|          |    50|       0|    0|\n",
      "|      801 STANYAN ST|       L|          |[37.767202,-122.4...|       RPD|      PPA|          |   324|       0|    0|\n",
      "+--------------------+--------+----------+--------------------+----------+---------+----------+------+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show 10 rows\n",
    "parking.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Query a Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parking.registerTempTable(\"park\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----+----------+\n",
      "|primetype|secondtype|count|avg_spaces|\n",
      "+---------+----------+-----+----------+\n",
      "|      PPA|          |  462|     210.0|\n",
      "|      PHO|          |  300|      69.0|\n",
      "|      CPO|          |  163|      53.0|\n",
      "|      CGO|          |   49|     135.0|\n",
      "|      PPA|       PHO|   19|     178.0|\n",
      "|      PPA|       CPO|    2|     263.0|\n",
      "|      PPA|       RPO|    1|      87.0|\n",
      "|      CPO|       PPA|    1|      12.0|\n",
      "|      PHO|       CPO|    1|     130.0|\n",
      "+---------+----------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run a SQL query against the table\n",
    "aggr_by_type = sqlContext.sql(\"SELECT primetype, secondtype, count(1) AS count, round(avg(regcap), 0) AS avg_spaces \" +\n",
    "                              \"FROM park \" +\n",
    "                              \"GROUP BY primetype, secondtype \" +\n",
    "                              \"HAVING trim(primetype) != '' \" +\n",
    "                              \"ORDER BY count DESC\")\n",
    "\n",
    "aggr_by_type.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(aggr_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can rewrite the SQL query in the previous example by chaining several simple DataFrame operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----+----------+\n",
      "|primetype|secondtype|count|avg_spaces|\n",
      "+---------+----------+-----+----------+\n",
      "|      PPA|          |  462|     210.0|\n",
      "|      PHO|          |  300|      69.0|\n",
      "|      CPO|          |  163|      53.0|\n",
      "|      CGO|          |   49|     135.0|\n",
      "|      PPA|       PHO|   19|     178.0|\n",
      "|      PPA|       CPO|    2|     263.0|\n",
      "|      PPA|       RPO|    1|      87.0|\n",
      "|      PHO|       CPO|    1|     130.0|\n",
      "|      CPO|       PPA|    1|      12.0|\n",
      "+---------+----------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "aggr_by_type = parking.select(\"primetype\", \"secondtype\", \"regcap\") \\\n",
    "    .where(\"trim(primetype) != ''\") \\\n",
    "    .groupBy(\"primetype\", \"secondtype\") \\\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"count\"),\n",
    "        F.round(F.avg(\"regcap\"), 0).alias(\"avg_spaces\")\n",
    "        ) \\\n",
    "    .sort(\"count\", ascending=False)\n",
    "\n",
    "aggr_by_type.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Describe and Crosstab to Summarize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+\n",
      "|summary|            regcap|          valetcap|             mccap|\n",
      "+-------+------------------+------------------+------------------+\n",
      "|  count|              1000|              1000|              1000|\n",
      "|   mean|           137.294|             3.297|             0.184|\n",
      "| stddev|361.05120902655835|22.624824279398833|1.9015151221485875|\n",
      "|    min|                 0|                 0|                 0|\n",
      "|    max|              9000|               430|                47|\n",
      "+-------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run describe - like in Pandas\n",
    "parking.describe(\"regcap\", \"valetcap\", \"mccap\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+---+---+---+---+\n",
      "|    owner_primetype|   |CGO|CPO|PHO|PPA|\n",
      "+-------------------+---+---+---+---+---+\n",
      "|         Port of SF|  0|  4|  0|  7|  7|\n",
      "|               SFPD|  0|  6|  0|  3|  0|\n",
      "|              SFMTA|  0|  0|  0| 14| 42|\n",
      "|GG Bridge Authority|  0|  0|  0|  0|  2|\n",
      "|               SFSU|  0|  0|  0|  6|  2|\n",
      "|               SFRA|  0|  0|  0|  0|  2|\n",
      "|                LHH|  0|  0|  0|  5|  0|\n",
      "|                DMV|  0|  0|  1|  0|  0|\n",
      "|           Caltrans|  0|  1|  0|  0|  0|\n",
      "|           Presidio|  0|  2|  1|  1|  5|\n",
      "+-------------------+---+---+---+---+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use crosstab\n",
    "parking.stat.crosstab(\"owner\", \"primetype\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Neighborhood Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define another function that will take a “location_1” struct type and use Google’s Geocoding API to perform a lookup on the latitude and longitude to return the neighborhood name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def to_neighborhood(location):\n",
    "    \"\"\"\n",
    "    Uses Google's Geocoding API to perform a reverse-lookup on latitude and\n",
    "    longitude\n",
    "    https://developers.google.com/maps/documentation/geocoding/\n",
    "    intro#reverse-example\n",
    "    \"\"\"\n",
    "    name = 'N/A'\n",
    "    lat = location.latitude\n",
    "    long = location.longitude\n",
    "\n",
    "    r = requests.get(\n",
    "        'https://maps.googleapis.com/maps/api/geocode/json?latlng=%s,%s' %(lat, long))\n",
    "\n",
    "    if r.status_code == 200:\n",
    "        content = r.json()\n",
    "        # results is a list of matching places\n",
    "        places = content['results']\n",
    "        neighborhoods = [p['formatted_address'] for p in places if\n",
    "        'neighborhood' in p['types']]\n",
    "\n",
    "    if neighborhoods:\n",
    "        # Addresses are formatted as Japantown, San Francisco, CA\n",
    "        # so split on comma and just return neighborhood name\n",
    "        name = neighborhoods[0].split(',')[0]\n",
    "\n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pyspark.sql.functions module provides the udf function to register a user-defined function (UDF). We declare an inline UDF by passing UDF a callable Python function and the Spark SQL data type that corresponds to the return type.\n",
    "\n",
    "In this case, we are returning a string so we will use the StringType data type from pyspark.sql.types. Once registered, we can use the UDF to reformat the “location_1” column with a withColumn expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+----------+--------+------+--------+-----+\n",
      "|        location_1|primetype|landusetyp|garorlot|regcap|valetcap|mccap|\n",
      "+------------------+---------+----------+--------+------+--------+-----+\n",
      "|   South of Market|      PPA|          |       G|  2585|       0|   47|\n",
      "|               N/A|      PPA|          |       G|  1865|       0|    0|\n",
      "|Financial District|      PPA|          |       G|  1095|       0|    0|\n",
      "|      Union Square|      PPA|          |       G|   985|       0|    0|\n",
      "|        Tenderloin|      PPA|          |       G|   925|       0|    0|\n",
      "|  Mission District|      PPA|          |       G|   850|       0|    0|\n",
      "|      Civic Center|      PPA|          |       G|   843|       0|    0|\n",
      "|  Mission District|      PPA|          |       G|   807|       0|    0|\n",
      "|       South Beach|      PPA|          |       G|   752|       0|    0|\n",
      "|         Japantown|      PPA|          |       G|   747|       0|    0|\n",
      "|         Chinatown|      PPA|          |       G|   700|       0|    0|\n",
      "| Fillmore District|      PPA|          |       G|   618|       0|    0|\n",
      "|         Chinatown|      PPA|          |       G|   600|       0|    0|\n",
      "|  Mission District|      PPA|          |       G|   350|       0|    0|\n",
      "|  Mission District|      PHO|          |       G|   227|       0|    0|\n",
      "|        Cow Hollow|      PPA|          |       G|   205|       0|    0|\n",
      "|         Japantown|      PPA|          |       G|   177|       0|    0|\n",
      "|      Russian Hill|      PPA|          |       G|   163|       0|    0|\n",
      "|      Russian Hill|      PPA|          |       G|   162|       0|    0|\n",
      "|Central Waterfront|      PHO|          |       L|   150|       0|    0|\n",
      "+------------------+---------+----------+--------+------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "location_to_neighborhood=udf(to_neighborhood, StringType())\n",
    "\n",
    "sfmta_parking = parking.filter(parking.owner == 'SFMTA') \\\n",
    "    .select(\"location_1\", \"primetype\", \"landusetyp\",\"garorlot\", \"regcap\", \"valetcap\", \"mccap\") \\\n",
    "    .withColumn(\"location_1\",location_to_neighborhood(\"location_1\")) \\\n",
    "    .sort(\"regcap\", ascending=False)\n",
    "\n",
    "sfmta_parking.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shut it down\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

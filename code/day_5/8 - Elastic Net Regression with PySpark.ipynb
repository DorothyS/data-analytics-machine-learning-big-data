{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElasticNet Regression with PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook creates and measures a linear regression model using sklearn.\n",
    "\n",
    "* Method: ElasticNet\n",
    "* Dataset: [California Housing](http://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Python core libs\n",
    "from os import getlogin, path, environ\n",
    "\n",
    "# Set SPARK_HOME\n",
    "# environ[\"SPARK_HOME\"] = \"/home/students/spark-2.2.0\"\n",
    "\n",
    "# Findspark\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "# PySpark and PySpark SQL\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import FloatType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# PySpark MLlib\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Some Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a SparkContext and a SQLContext context to use\n",
    "sc = SparkContext(appName=\"Linear Regression with Spark\")\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data \n",
    "DATA_FILE = \"/Users/robert.dempsey/Dev/daamlobd/data/CaliforniaHousing/cal_housing.data\"\n",
    "HEADER_FILE = \"/Users/robert.dempsey/Dev/daamlobd/data/CaliforniaHousing/cal_housing.domain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prepare the columns\n",
    "headers = sc.textFile(HEADER_FILE)\n",
    "cols = [col.split(\":\")[0] for col in list(headers.collect())]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import the data\n",
    "data = sqlContext.read.csv(DATA_FILE)\n",
    "\n",
    "# Rename the columns\n",
    "data = data.toDF('longitude', 'latitude', 'housingMedianAge','totalRooms', 'totalBedrooms',\n",
    "                 'population', 'households', 'medianIncome', 'medianHouseValue')\n",
    "\n",
    "# Show the top two rows\n",
    "data.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# View the schema\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a user defined function (UDF) to convert the column types\n",
    "def convert_column_type(df, names, new_type):\n",
    "    for name in names: \n",
    "        df = df.withColumn(name, df[name].cast(new_type))\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert the columns to the correct types\n",
    "data = convert_column_type(data, data.columns, FloatType())\n",
    "\n",
    "# View the schema\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Describe the data - convert to Pandas dataframe to make it prettier\n",
    "data_pd = data.describe().toPandas()\n",
    "data_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: the difference between many of the min and max values are large so we'll need to normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dependent variable, medianHouseValue, to use units of 100000\n",
    "data = data.withColumn(\"medianHouseValue\", F.col(\"medianHouseValue\")/100000)\n",
    "data.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Add additional features to the dataframe:\n",
    "* Rooms per household: number of rooms in a household per block group\n",
    "* Population per household: an indication of how many people live in households per block group\n",
    "* Bedrooms per room: how many rooms are bedrooms per block group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the columns to the dataframe\n",
    "data = data.withColumn(\"roomsPerHousehold\", F.col(\"totalRooms\")/F.col(\"households\")) \\\n",
    "           .withColumn(\"populationPerHousehold\", F.col(\"population\")/F.col(\"households\")) \\\n",
    "           .withColumn(\"bedroomsPerRoom\", F.col(\"totalBedRooms\")/F.col(\"totalRooms\"))\n",
    "        \n",
    "# View the first row\n",
    "data.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataframe for analysis by reordering and selecting a subset of the columns\n",
    "# Move our target variable to the first column to make it easy to extract\n",
    "data = data.select(\"medianHouseValue\",\n",
    "                   \"totalBedRooms\", \n",
    "                   \"population\", \n",
    "                   \"households\", \n",
    "                   \"medianIncome\", \n",
    "                   \"roomsPerHousehold\", \n",
    "                   \"populationPerHousehold\", \n",
    "                   \"bedroomsPerRoom\")\n",
    "data.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and a label (target)\n",
    "# DenseVector: used to store arrays of values for use in PySpark\n",
    "input_data = data.rdd.map(lambda x: (x[0], DenseVector(x[1:])))\n",
    "\n",
    "# Replace the dataframe with the new dataframe\n",
    "data = sqlContext.createDataFrame(input_data, [\"label\", \"features\"])\n",
    "\n",
    "# Show the top row\n",
    "data.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data using the StandardScaler\n",
    "standardScaler = StandardScaler(inputCol=\"features\", outputCol=\"features_scaled\")\n",
    "\n",
    "# Fit the dataframe to the scaler\n",
    "scaler = standardScaler.fit(data)\n",
    "\n",
    "# Transform the data in the dataframe with the scaler\n",
    "scaled_df = scaler.transform(data)\n",
    "\n",
    "# Inspect the result\n",
    "scaled_df.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "# The seed gives us reproducability of results\n",
    "X_train, X_test = scaled_df.randomSplit([.8, .2], seed=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model parameters:\n",
    "* maxIter: max number of iterations to run the optimization algorithm (gradient descent)\n",
    "* regParam: regularization parameter\n",
    "* elasticNetParam: elastic net parameter\n",
    "  * 1 = L1 (LASSO)\n",
    "  * 0 = L2 (Ridge)\n",
    "  * Between 0 and 1 = ElasticNet\n",
    "\n",
    "Below we train an elastic net regularized linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of a LinearRegression model\n",
    "lr = LinearRegression(labelCol=\"label\", maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "# Fit the data to the model\n",
    "trained_model = lr.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intercept for the model\n",
    "print('Estimated intercept coefficient: {}'.format(trained_model.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with the features and coefficients\n",
    "feature_columns = [\"totalBedRooms\", \"population\", \"households\", \"medianIncome\", \"roomsPerHousehold\",\n",
    "                   \"populationPerHousehold\", \"bedroomsPerRoom\"]\n",
    "coefficients = [float(coef) for coef in trained_model.coefficients]\n",
    "\n",
    "cols_coefs = list(zip(feature_columns, coefficients))\n",
    "\n",
    "c_df = sqlContext.createDataFrame(cols_coefs, [\"feature\", \"coefficient\"])\n",
    "c_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**: it appears there is a weak correlation between medianIncome and medianHouseValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot for medianIncome and medianHouseValue\n",
    "median_house_values = X_train.select('label').collect()\n",
    "median_incomes = [row[0][4] for row in X_train.select('features').collect()]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.scatter(median_incomes, median_house_values)\n",
    "plt.xlabel(\"Median Income\")\n",
    "plt.ylabel(\"Median House Value\")\n",
    "plt.title(\"Relationship between Median Income and Median House Value\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the transform() method to predict labels for the test data\n",
    "predicted = trained_model.transform(X_test)\n",
    "\n",
    "# Extract the predictions and the known correct labels\n",
    "predictions = predicted.select(\"prediction\").rdd.map(lambda x: x[0])\n",
    "labels = predicted.select(\"label\").rdd.map(lambda x: x[0])\n",
    "\n",
    "# Zip the predictions and labels into a list\n",
    "predictions_and_labels = predictions.zip(labels).collect()\n",
    "\n",
    "# Print the first five records (actual value, predicted value)\n",
    "predictions_and_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Plot this shit.\n",
    "predicted.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add a plot\n",
    "# Create a plot to compare actual median house values and the predicted median house values\n",
    "# fig = plt.figure(figsize=(20,10))\n",
    "# plt.scatter(Y_test, y_pred)\n",
    "# plt.xlabel(\"Actual Median House Value: $Y_i$\")\n",
    "# plt.ylabel(\"Predicted Median House Value: $\\hat{Y}_i$\")\n",
    "# plt.title(\"Actual vs. Predicted Median House Values: $Y_i$ vs. $\\hat{Y}_i$\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Mean Squared Error\n",
    "\n",
    "* An absolute measure of fit\n",
    "* The distance, on average, of a data point from the fitted line, measured along a vertical line.\n",
    "* Measured in the same units as the response variable\n",
    "* Gives a relatively height weight to large errors; mor euseful when large errors are particulary undesirable\n",
    "* Values closer to zero (0) are better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = trained_model.summary.rootMeanSquaredError\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance (R^2)\n",
    "\n",
    "* Explains how much of the variability of a factor can be caused or explained by its relationship to another factor; how well the model is predicting.\n",
    "* A score of 1 means a perfect prediction\n",
    "* A score of 0 means the model always predicts the expected value of y, disregarding the input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = trained_model.summary.r2\n",
    "print(\"Variance Score: %.2f\" % r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the high RMSE and median R2 scores the model needs some help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees with PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook creates and measures a [Decision Tree](https://spark.apache.org/docs/2.2.0/mllib-decision-tree.html) model with PySpark.\n",
    "\n",
    "* Method: Decision Tree\n",
    "* Dataset: MLlib Sample Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "from pyspark.mllib.tree import DecisionTree\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Some Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SparkContext and a SQLContext context to use\n",
    "sc = SparkContext(appName=\"Decision Tree Classification with Spark\")\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = \"/Users/robert.dempsey/Dev/daamlobd/data/mllib/sample_libsvm_data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "data = MLUtils.loadLibSVMFile(sc, path=DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show one of the records\n",
    "data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test datasets\n",
    "train, test = data.randomSplit([0.8, 0.2], 42)\n",
    "print(train.count(), test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a Decision Tree Model\n",
    "\n",
    "Arguments\n",
    "* numClasses: number of classes\n",
    "* categoricalFeaturesInfo: specifies which features are categorical and how many categorical values each of those features can take.\n",
    "* impurity: a measure of the homogeneity of the labels at the node; options: gini and entropy\n",
    "* maxDepth: maximum depth of the tree\n",
    "* maxBins: number of bins used when discretizing continuous features.\n",
    "  * More = allows the algo to consider more split candidtates and make fine-grained split decisions; increases computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTree.trainClassifier(train,\n",
    "                                     numClasses=2,\n",
    "                                     categoricalFeaturesInfo={},\n",
    "                                     impurity='gini',\n",
    "                                     maxDepth=5,\n",
    "                                     maxBins=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test.map(lambda x: x.features))\n",
    "labels_and_predictions = test.map(lambda lp: lp.label).zip(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels_and_predictions and the test RDD to dataframes\n",
    "lp_df = sqlContext.createDataFrame(labels_and_predictions, [\"label\", \"predicted\"])\n",
    "test_df = sqlContext.createDataFrame(test, [\"features\", \"label\"])\n",
    "\n",
    "# Make sure they have the same number of records\n",
    "print(lp_df.count(), test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataframes\n",
    "print(lp_df.show(5))\n",
    "print(test_df.show(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot to compare the actuals (labels) and predictions\n",
    "actuals = lp_df.rdd.map(lambda r: r.label).collect()\n",
    "predictions = lp_df.rdd.map(lambda r: float(r.predicted)).collect()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.scatter(actuals, predictions)\n",
    "plt.xlabel(\"Actuals\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.title(\"Actuals vs. Predictions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Error\n",
    "\n",
    "Calculate the training error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_error = labels_and_predictions.filter(lambda lp: lp[0] != lp[1]).count() / float(test.count())\n",
    "print(\"Training Error = %.2f\" % training_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.toDebugString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shut it Down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Clustering with PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to implement and measure a Latent Dirichlet Allocation (LDA) topic model for clustering documents.\n",
    "\n",
    "* Method: [LDA](https://spark.apache.org/docs/2.2.0/api/python/pyspark.ml.html#pyspark.ml.clustering.LDA)\n",
    "* Dataset: MLlib sample LDA data\n",
    "\n",
    "Terminology:\n",
    "* term = \"word\": an el\n",
    "* token: instance of a term appearing in a document\n",
    "* topic: multinomial distribution over terms representing some concept\n",
    "* document: one piece of text, corresponding to one row in the input data\n",
    "\n",
    "**NOTE**: this feature is experimental and under active development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "# Set SPARK_HOME\n",
    "# environ[\"SPARK_HOME\"] = \"/home/students/spark-2.2.0\"\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "from pyspark.ml.clustering import LDA\n",
    "from sklearn import metrics\n",
    "\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 10, 8\n",
    "sb.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Some Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SparkContext and a SQLContext context to use\n",
    "sc = SparkContext(appName=\"LDA Clustering with Spark\")\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = \"/Users/robert.dempsey/Dev/daamlobd/data/mllib/sample_lda_libsvm_data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sqlContext.read.format(\"libsvm\").load(DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View one of the records\n",
    "data.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify the Number of Clusters and Optimizer to Use\n",
    "\n",
    "Arguments:\n",
    "* k: number of topics (clusters)\n",
    "* seed: random seed\n",
    "* optimizer: Optimizer or inference algorithm used to estimate the LDA model\n",
    "  * online\n",
    "  * em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of tuples to test cluster ranges with different linkages\n",
    "cluster_range = range(2, 11)\n",
    "optimizer = ['online', 'em']\n",
    "\n",
    "cluster_range_optimizer = list(product(cluster_range, optimizer))\n",
    "print(cluster_range_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of LDA models\n",
    "lda_models = [LDA(k=i[0], optimizer=i[1], maxIter=50) for i in cluster_range_optimizer]\n",
    "print(len(lda_models))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics\n",
    "* logLikelihood: a lower bound on the log likelihood of the entire corpus\n",
    "* logPerplexity: calculate an upper bound on perplexity (lower is better)\n",
    "\n",
    "Perplexity is a measurement of how well a probability distribution or probability model predicts a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each model, fit it to the data and get the logPerplexity score\n",
    "cluster_ll_scores = list()\n",
    "cluster_lp_scores = list()\n",
    "\n",
    "# Fit each of the models on the data\n",
    "for lda_model in lda_models:\n",
    "    model = lda_model.fit(data)\n",
    "    ll = model.logLikelihood(data)\n",
    "    lp = model.logPerplexity(data)\n",
    "    cluster_ll_scores.append(lp)\n",
    "    cluster_lp_scores.append(lp)\n",
    "\n",
    "# Show one of the LP scores\n",
    "cluster_lp_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatterplot of the LL and LP scores\n",
    "plt.scatter(cluster_ll_scores, cluster_lp_scores)\n",
    "plt.title(\"logPerplexity and logLikelihood Scores\")\n",
    "plt.xlabel(\"logLikelihood\")\n",
    "plt.ylabel(\"logPerplexity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot an barchart of the LP scores\n",
    "chart_labels = [\"{}_{}\".format(i[0], i[1]) for i in cluster_range_optimizer]\n",
    "\n",
    "sb.barplot(y=chart_labels, x=cluster_lp_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: based on the graph above it appears that 2 clusters using online optimization has the best logPerplexity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index value of the min cluster lp score\n",
    "min_score_index = cluster_lp_scores.index(min(cluster_lp_scores))\n",
    "\n",
    "# Get the number of clusters used for the model with the min score\n",
    "params_to_use = cluster_range_optimizer[min_score_index]\n",
    "\n",
    "print(\"Number of topics: {}\".format(params_to_use[0]))\n",
    "print(\"Optimizer: {}\".format(params_to_use[1]))## Fit a Hierarchical Clustering Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit an LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "lda_model = LDA(k=params_to_use[0], optimizer=params_to_use[1], maxIter=50)\n",
    "model = lda_model.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Model Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logLikelihood and logPerplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = model.logLikelihood(data)\n",
    "lp = model.logPerplexity(data)\n",
    "print(\"The lower bound on the log likelihood of the entire corpus: \" + str(ll))\n",
    "print(\"The upper bound on perplexity: \" + str(lp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = model.describeTopics(3)\n",
    "print(\"The topics described by their top-weighted terms:\")\n",
    "topics.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shut it Down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
